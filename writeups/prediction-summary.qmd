---
title: "Predictive modeling of claims status"
author: 'YOUR NAMES HERE'
date: today
---

### Abstract

Provide a 3-5 sentence summary of your work on the primary task. Indicate what input data was used, what method was used for binary class predictions, what method was used for multiclass predictions, and what estimated accuracies were achieved.

> *Header and paragraph content was scraped from the raw webpages and processed into term frequencies of word tokens. For binary classification, a two-layer neural network yielded an estimated 81.4% accuracy; for multiclass classification, a support vector machine gave 78% accuracy.*

### Preprocessing

In one paragraph lay out your preprocessing pipeline. No need to provide exact step-by-step detail; just give an overview of the main components:

-   what text content was extracted from HTML

-   how text was cleaned

-   how cleaned text was represented quantitatively

For the binary classification task, we employed a deep learning approach using a sequential neural network in Keras. The model begins with a layer_text_vectorization to convert raw text into integer sequences, with a maximum vocabulary of 20,000 tokens and a fixed sequence length of 200. The vectorized text is passed through an embedding layer of dimension 64 to create dense word representations, followed by a bidirectional LSTM with 32 units to capture contextual information from both directions of the text. The sequential output is then processed through a dense layer of 32 units with ReLU activation before reaching the final single-unit output layer with a sigmoid activation function for binary prediction. The model was compiled using the Adam optimizer, binary crossentropy loss, and accuracy as the evaluation metric. Training was performed for 5 epochs with a batch size of 32, using 20% of the training data as a validation split.

For the multiclass classification task, a deep learning approach using a sequential neural network was employed. The model begins with a text vectorization layer that converts raw text into integer sequences with a vocabulary limit of 20,000 tokens and a fixed sequence length of 200. This is followed by an embedding layer of dimension 64 to create dense vector representations of the tokens. A bidirectional LSTM layer with 32 units captures sequential dependencies from both forward and backward directions in the text. The output is then passed through a fully connected dense layer with 32 units and ReLU activation, and finally through a dense softmax layer with 5 units to produce probabilities for each of the five classes. The model was trained using the Adam optimizer, with a sparse categorical cross-entropy loss suitable for integer-encoded labels, over 8 epochs and a validation split of 20% of the training data. Hyperparameters, including embedding dimension, LSTM units, and dense layer size, were chosen to balance model complexity and overfitting, given the size of the training dataset.

### Methods

Describe your final predictive models. Include one paragraph with details on the binary classification approach, and one on the multiclass approach. Include for each:

-   what ML/statistical method was used

-   model specification and hyperparameter selection

-   training method

### Results

Indicate the predictive accuracy of the binary classifications and the multiclass classifications. Provide a table for each, and report sensitivity, specificity, and accuracy.[^1]

[^1]: Read [this article](https://yardstick.tidymodels.org/articles/multiclass.html) on multiclass averaging.
